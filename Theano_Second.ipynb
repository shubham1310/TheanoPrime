{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will Come back to this and understand it in detail\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "k = T.iscalar(\"k\")\n",
    "A = T.vector(\"A\")\n",
    "\n",
    "# Symbolic description of the result\n",
    "result, updates = theano.scan(fn=lambda prior_result, A: prior_result * A,\n",
    "                              outputs_info=T.ones_like(A),\n",
    "                              non_sequences=A,\n",
    "                              n_steps=k)\n",
    "\n",
    "# We only care about A**k, but scan has provided us with A**1 through A**k.\n",
    "# Discard the values that we don't care about. Scan is smart enough to\n",
    "# notice this and not waste memory saving them.\n",
    "final_result = result[-1]\n",
    "\n",
    "# compiled function that returns A**k\n",
    "power = theano.function(inputs=[A,k], outputs=final_result, updates=updates)\n",
    "\n",
    "print \"We will Come back to this and understand it in detail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   1.   4.   9.  16.  25.  36.  49.  64.  81.]\n",
      "[ 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(power(range(10),2))\n",
    "print(power(range(1),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's the lambda thing ?\n",
    "fn=lambda prior_result, A: prior_result * A\n",
    "fn(4,2)\n",
    "# It is basically functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accumulation\n",
    "### In the scan operator, the first parameter of the lambda function is the  accumulated variable from the last iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = T.scalar()\n",
    "\n",
    "acc,upd = theano.scan(fn = lambda temp : temp + 1, outputs_info=theano.shared(np.zeros(1)),n_steps=k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Temp accumulates the result.\n",
    "\n",
    "* outputs_info stores the initial value of the accumulator\n",
    "\n",
    "* n_steps tells the number of iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc_fn = theano.function([k],acc,updates=upd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hence, the parameter here is only the number of times to add 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n",
      " [ 2.]\n",
      " [ 3.]]\n"
     ]
    }
   ],
   "source": [
    "print acc_fn(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = T.scalar()\n",
    "inc = T.scalar()\n",
    "acc,upd = theano.scan(fn = lambda temp, inc : temp + inc, outputs_info=theano.shared(np.zeros(1)),non_sequences = inc, n_steps=k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __inc__ is a scalar, which is added to the accumulator in each iteration\n",
    "* In a for loop, you can equate __non_sequences__ to variables that is used wholly in each iteration\n",
    "> Consider this C for  loop\n",
    ">  <pre><code> for (i = 1; i < 10; i++)\n",
    " >   sum = sum + a\n",
    " > </pre></code>\n",
    "\n",
    "* Here , a is added in each iteration. These variables go in the non_sequences block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "acc_fn = theano.function([inc,k],acc,updates=upd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ So, now we have two parameters __inc__ and __k__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.],\n",
       "       [ 4.],\n",
       "       [ 6.]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_fn(2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can have more non_sequence variables\n",
    "> Consider the following piece of code\n",
    "> <pre> <code> for (i = 1; i < k ; i++)\n",
    ">        x = x * s + t \n",
    "       </code></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = T.scalar('s')\n",
    "t = T.scalar('t')\n",
    "def odd_inc(x,s,t):\n",
    "    x = x * s + t\n",
    "    return x\n",
    "\n",
    "acc,upd = theano.scan(fn = odd_inc, outputs_info=theano.shared(np.zeros(1)),non_sequences = [t,s], n_steps=k)\n",
    "\n",
    "acc_fn = theano.function([s,k,t],acc,updates=upd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2.],\n",
       "       [  10.],\n",
       "       [  42.],\n",
       "       [ 170.],\n",
       "       [ 682.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_fn(2,5,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Accumulation\n",
    "\n",
    "#### If there no accumulation of results, we can set __outputs_info__ to None. This indicates to scan that it doesnâ€™t need to pass the prior result to fn. ####\n",
    "\n",
    "> The general order of function parameters to fn is:\n",
    "\n",
    "> <pre><code>fn(sequences (if any), prior result(s) (if needed), non-sequences (if any))</code></pre>\n",
    "\n",
    "### Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = T.vector('s')\n",
    "t = T.vector('t')\n",
    "\n",
    "def vec_mul(s,t):\n",
    "    x = s * t\n",
    "    return x\n",
    "\n",
    "acc,upd = theano.scan(fn = vec_mul, outputs_info = None, sequences = [s,t])\n",
    "\n",
    "acc_fn = theano.function([s,t],acc,updates=upd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And then sum up the results\n",
    "> We do an elementwise multiplication and then add them up\n",
    "\n",
    "Equate this with the following block of code \n",
    "> <pre> <code> for (i = 1; i< 10; i++)\n",
    ">         x[i] = s[i] * t[i]\n",
    "</code> </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_fn(np.asarray([3,1,2]),np.asarray([2,2,2])).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note the order of arguements in vec_mul().\n",
    "> Try and see what happens if you put s at the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = T.vector('s')\n",
    "t = T.vector('t')\n",
    "def vec_mul(s,t,x):\n",
    "    v =  s * t\n",
    "    return v\n",
    "outputs_info = T.as_tensor_variable(np.asarray(0, np.float64))\n",
    "acc,upd = theano.scan(fn = vec_mul, outputs_info = outputs_info, sequences = [s,t])\n",
    "\n",
    "acc_fn = theano.function([s,t],acc,updates=upd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.,   8.,  15.])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_fn([3,2,3],[2, 4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    \"\"\"Multi-class Logistic Regression Class\n",
    "\n",
    "    The logistic regression is fully described by a weight matrix :math:`W`\n",
    "    and bias vector :math:`b`. Classification is done by projecting data\n",
    "    points onto a set of hyperplanes, the distance to which is used to\n",
    "    determine a class membership probability.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input, n_in, n_out):\n",
    "        \"\"\" Initialize the parameters of the logistic regression\n",
    "\n",
    "        :type input: theano.tensor.TensorType\n",
    "        :param input: symbolic variable that describes the input of the\n",
    "                      architecture (one minibatch)\n",
    "\n",
    "        :type n_in: int\n",
    "        :param n_in: number of input units, the dimension of the space in\n",
    "                     which the datapoints lie\n",
    "\n",
    "        :type n_out: int\n",
    "        :param n_out: number of output units, the dimension of the space in\n",
    "                      which the labels lie\n",
    "\n",
    "        \"\"\"\n",
    "        # start-snippet-1\n",
    "        # initialize with 0 the weights W as a matrix of shape (n_in, n_out)\n",
    "        self.W = theano.shared(\n",
    "            value=np.zeros(\n",
    "                (n_in, n_out),\n",
    "                dtype=theano.config.floatX\n",
    "            ),\n",
    "            name='W',\n",
    "            borrow=True\n",
    "        )\n",
    "        # initialize the biases b as a vector of n_out 0s\n",
    "        self.b = theano.shared(\n",
    "            value=np.zeros(\n",
    "                (n_out,),\n",
    "                dtype=theano.config.floatX\n",
    "            ),\n",
    "            name='b',\n",
    "            borrow=True\n",
    "        )\n",
    "\n",
    "        # symbolic expression for computing the matrix of class-membership\n",
    "        # probabilities\n",
    "        # Where:\n",
    "        # W is a matrix where column-k represent the separation hyperplane for\n",
    "        # class-k\n",
    "        # x is a matrix where row-j  represents input training sample-j\n",
    "        # b is a vector where element-k represent the free parameter of\n",
    "        # hyperplane-k\n",
    "        self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W) + self.b)\n",
    "\n",
    "        # symbolic description of how to compute prediction as class whose\n",
    "        # probability is maximal\n",
    "        self.y_pred = T.argmax(self.p_y_given_x, axis=1)\n",
    "        # end-snippet-1\n",
    "\n",
    "        # parameters of the model\n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "        # keep track of model input\n",
    "        self.input = input\n",
    "\n",
    "    def negative_log_likelihood(self, y):\n",
    "        \"\"\"Return the mean of the negative log-likelihood of the prediction\n",
    "        of this model under a given target distribution.\n",
    "\n",
    "        .. math::\n",
    "\n",
    "            \\frac{1}{|\\mathcal{D}|} \\mathcal{L} (\\theta=\\{W,b\\}, \\mathcal{D}) =\n",
    "            \\frac{1}{|\\mathcal{D}|} \\sum_{i=0}^{|\\mathcal{D}|}\n",
    "                \\log(P(Y=y^{(i)}|x^{(i)}, W,b)) \\\\\n",
    "            \\ell (\\theta=\\{W,b\\}, \\mathcal{D})\n",
    "\n",
    "        :type y: theano.tensor.TensorType\n",
    "        :param y: corresponds to a vector that gives for each example the\n",
    "                  correct label\n",
    "\n",
    "        Note: we use the mean instead of the sum so that\n",
    "              the learning rate is less dependent on the batch size\n",
    "        \"\"\"\n",
    "        # start-snippet-2\n",
    "        # y.shape[0] is (symbolically) the number of rows in y, i.e.,\n",
    "        # number of examples (call it n) in the minibatch\n",
    "        # T.arange(y.shape[0]) is a symbolic vector which will contain\n",
    "        # [0,1,2,... n-1] T.log(self.p_y_given_x) is a matrix of\n",
    "        # Log-Probabilities (call it LP) with one row per example and\n",
    "        # one column per class LP[T.arange(y.shape[0]),y] is a vector\n",
    "        # v containing [LP[0,y[0]], LP[1,y[1]], LP[2,y[2]], ...,\n",
    "        # LP[n-1,y[n-1]]] and T.mean(LP[T.arange(y.shape[0]),y]) is\n",
    "        # the mean (across minibatch examples) of the elements in v,\n",
    "        # i.e., the mean log-likelihood across the minibatch.\n",
    "        return -T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[0]), y])\n",
    "        # end-snippet-2\n",
    "\n",
    "    def errors(self, y):\n",
    "        \"\"\"Return a float representing the number of errors in the minibatch\n",
    "        over the total number of examples of the minibatch ; zero one\n",
    "        loss over the size of the minibatch\n",
    "\n",
    "        :type y: theano.tensor.TensorType\n",
    "        :param y: corresponds to a vector that gives for each example the\n",
    "                  correct label\n",
    "        \"\"\"\n",
    "\n",
    "        # check if y has same dimension of y_pred\n",
    "        if y.ndim != self.y_pred.ndim:\n",
    "            raise TypeError(\n",
    "                'y should have the same shape as self.y_pred',\n",
    "                ('y', y.type, 'y_pred', self.y_pred.type)\n",
    "            )\n",
    "        # check if y is of the correct datatype\n",
    "        if y.dtype.startswith('int'):\n",
    "            # the T.neq operator returns a vector of 0s and 1s, where 1\n",
    "            # represents a mistake in prediction\n",
    "            return T.mean(T.neq(self.y_pred, y))\n",
    "        else:\n",
    "            raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    # generate symbolic variables for input (x and y represent a\n",
    "    # minibatch)\n",
    "    x = T.matrix('x')  # data, presented as rasterized images\n",
    "    y = T.ivector('y')  # labels, presented as 1D vector of [int] labels\n",
    "\n",
    "    # construct the logistic regression class\n",
    "    # Each MNIST image has size 28*28\n",
    "    classifier = LogisticRegression(input=x, n_in=28 * 28, n_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # the cost we minimize during training is the negative log likelihood of\n",
    "    # the model in symbolic format\n",
    "    cost = classifier.negative_log_likelihood(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the gradients for bias and weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g_W = T.grad(cost=cost, wrt=classifier.W)\n",
    "g_b = T.grad(cost=cost, wrt=classifier.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # specify how to update the parameters of the model as a list of\n",
    "    # (variable, update expression) pairs.\n",
    "learning_rate = T.scalar('lr')\n",
    "updates = [(classifier.W, classifier.W - learning_rate * g_W),\n",
    "               (classifier.b, classifier.b - learning_rate * g_b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n"
     ]
    }
   ],
   "source": [
    "from logistic_sgd import load_data\n",
    "import os\n",
    "\n",
    "dataset='mnist.pkl.gz'\n",
    "\n",
    "datasets = load_data(dataset)\n",
    "batch_size = 500\n",
    "\n",
    "\n",
    "train_set_x, train_set_y = datasets[0]\n",
    "valid_set_x, valid_set_y = datasets[1]\n",
    "test_set_x, test_set_y = datasets[2]\n",
    "\n",
    "# compute number of minibatches for training, validation and testing\n",
    "n_train_batches = train_set_x.get_value(borrow=True).shape[0] // batch_size\n",
    "n_valid_batches = valid_set_x.get_value(borrow=True).shape[0] // batch_size\n",
    "n_test_batches = test_set_x.get_value(borrow=True).shape[0] // batch_size\n",
    "    \n",
    "index = T.lscalar('index')\n",
    "# compiling a Theano function `train_model` that returns the cost, but in\n",
    "    # the same time updates the parameter of the model based on the rules\n",
    "    # defined in `updates`\n",
    "train_model = theano.function(\n",
    "        inputs=[index,learning_rate],\n",
    "        outputs=cost,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            x: train_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: train_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets create the validation and the test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_model = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=classifier.errors(y),\n",
    "        givens={\n",
    "            x: test_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: test_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "\n",
    "validate_model = theano.function(\n",
    "        inputs=[index],\n",
    "        outputs=classifier.errors(y),\n",
    "        givens={\n",
    "            x: valid_set_x[index * batch_size: (index + 1) * batch_size],\n",
    "            y: valid_set_y[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_losses = [test_model(i)\n",
    "                                   for i in range(n_test_batches)]\n",
    "test_score = np.mean(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2036"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_losses = [validate_model(i)\n",
    "                                     for i in range(n_valid_batches)]\n",
    "this_validation_loss = np.mean(validation_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2036\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    for minibatch_index in range(n_train_batches):\n",
    "                minibatch_avg_cost = train_model(minibatch_index,0.0001)\n",
    "test_losses = [test_model(i)\n",
    "                                   for i in range(n_test_batches)]\n",
    "test_score = np.mean(test_losses)\n",
    "print test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def predict(i):\n",
    "    \"\"\"\n",
    "    An example of how to load a trained model and use it\n",
    "    to predict labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # load the saved model\n",
    "    classifier = pickle.load(open('best_model.pkl'))\n",
    "\n",
    "    # compile a predictor function\n",
    "    predict_model = theano.function(\n",
    "        inputs=[classifier.input],\n",
    "        outputs=classifier.y_pred)\n",
    "\n",
    "    # We can test it on some examples from test test\n",
    "    dataset='mnist.pkl.gz'\n",
    "    datasets = load_data(dataset)\n",
    "    test_set_x, test_set_y = datasets[2]\n",
    "    test_set_x = test_set_x.get_value()\n",
    "    plt.imshow(test_set_x[i-1].reshape(28,28),cmap='Greys')\n",
    "    plt.show()\n",
    "\n",
    "    predicted_values = predict_model(test_set_x[i-1:i])\n",
    "    return predicted_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYX6P5lGrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f72133f2390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THe label for the figure is [5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "with open('best_model.pkl', 'wb') as f:\n",
    "                        pickle.dump(classifier, f)\n",
    "        \n",
    "number = 103\n",
    "a = predict(number)\n",
    "print \"THe label for the figure is \"+ str(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create a RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import sys\n",
    "\n",
    "dtype = theano.config.floatX\n",
    "learning_rate = 0.05\n",
    "n_in = 256\n",
    "n_hid = 1000\n",
    "n_out = 256\n",
    "n_epoch = 10\n",
    "\n",
    "\n",
    "def sample_weights(SizeX, SizeY):\n",
    "    values = np.ndarray([SizeX, SizeY], dtype = dtype)\n",
    "    for dx in range(SizeX):\n",
    "        row_val = np.random.normal(loc = 0.0, scale = 0.1, size=(SizeY,))\n",
    "        values[dx,:] = row_val\n",
    "    _,svs,_ = np.linalg.svd(values)\n",
    "    values = values / svs[0]\n",
    "    return values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_parameters(n_in, n_hid, n_out):\n",
    "    b_out = theano.shared(np.zeros(n_out, dtype = dtype))\n",
    "    b_hid = theano.shared(np.zeros(n_hid, dtype = dtype))\n",
    "    W_ih = theano.shared(sample_weights(n_in, n_hid))\n",
    "    W_hh = theano.shared(sample_weights(n_hid, n_hid))\n",
    "    W_ho = theano.shared(sample_weights(n_hid, n_out))\n",
    "    h_0 = theano.shared(np.zeros(n_hid, dtype = dtype))\n",
    "    return h_0, b_out, b_hid, W_ih, W_hh, W_ho\n",
    "\n",
    "def logistic_function(vec):\n",
    "    return 1/(1 + T.exp(-vec))\n",
    "def activ_tan(vec):\n",
    "    return T.tanh(vec)\n",
    "def one_step(x_t, hid_s, W_ih, W_hh, W_ho, b_out, b_hid):\n",
    "    h_t = activ_tan(theano.dot(x_t, W_ih) + theano.dot(hid_s, W_hh) + b_hid)\n",
    "    return h_t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hid_s, b_out, b_hid, W_ih, W_hh, W_ho = generate_parameters(n_in,n_hid,n_out)\n",
    "\n",
    "params = [ b_out, b_hid, W_ih, W_hh, W_ho]\n",
    "\n",
    "x_t = theano.shared(np.random.uniform(size = n_in))\n",
    "\n",
    "inp = T.matrix(dtype = dtype)\n",
    "\n",
    "target = T.matrix(dtype = dtype)\n",
    "\n",
    "hidden_s,_ = theano.scan(fn = one_step, sequences=inp, outputs_info = hid_s, non_sequences = [ W_ih, W_hh, W_ho, b_out, b_hid])\n",
    "\n",
    "#hid_s = hidden_s[hidden_s.shape[0]-1]\n",
    "\n",
    "y_t = theano.dot(hidden_s[hidden_s.shape[0]-1], W_ho) + b_out\n",
    "\n",
    "p_y_given_x = T.nnet.softmax(y_t)\n",
    "\n",
    "y_t = T.argmax(p_y_given_x, axis = 1)\n",
    "\n",
    "lr = theano.shared(np.cast[dtype](learning_rate))\n",
    "\n",
    "cost = -T.sum(target*T.log(p_y_given_x) + (1.- target)*T.log(1. - p_y_given_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_graph(target, inp, cost):\n",
    "    grads = []\n",
    "    for param in params:\n",
    "        grads.append(T.grad(cost, param))\n",
    "    update = []\n",
    "    for param,grad in zip(params, grads):\n",
    "        update.append((param, param - grad*lr))\n",
    "    train_fn = theano.function(inputs = [inp,target], outputs = cost, updates = update)\n",
    "    return train_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_pred_graph(inp):\n",
    "    predictions = theano.function(inputs = [inp], outputs = y_t, updates = [(hid_s, hidden_s[hidden_s.shape[0]-1])])\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def convert_string(file):\n",
    "    f = open(file,'r')\n",
    "    text = f.read()\n",
    "    f.close()\n",
    "    inp = np.zeros([len(text), 256],dtype=dtype)\n",
    "    out = np.zeros([len(text), 256],dtype=dtype)\n",
    "    counter = 0\n",
    "    for char in text:\n",
    "        if(counter > 0):\n",
    "            inp[counter][ord(char)] = 1\n",
    "            out[counter-1][ord(char)] = 1\n",
    "        counter = counter + 1\n",
    "    return [inp, out]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "learn_rnn_fn = get_train_graph(target, inp, cost)\n",
    "pred_rnn_fn = get_pred_graph(inp)\n",
    "\n",
    "train_data = convert_string(\"log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j = 0\n",
    "def train_rnn(train_data, n_epoch = 100):\n",
    "    train_err = np.ndarray(n_epoch)\n",
    "    for i in range(n_epoch):\n",
    "        for j in range(len(train_data[0])):\n",
    "            tempInp = np.zeros([1,256],dtype=dtype);\n",
    "            tempInp[0] = train_data[0][j]\n",
    "            tempOut = np.zeros([1,256],dtype=dtype);\n",
    "            tempOut[0] = train_data[1][j]\n",
    "            train_cost = learn_rnn_fn(tempInp, tempOut)\n",
    "            sys.stdout.write(chr(pred_rnn_fn(tempInp)))\n",
    "            train_err[i]=train_err[i]+ train_cost\n",
    "        train_err[i]= train_err[i]/len(train_data[0])\n",
    "        print \"\"\n",
    "        if train_err[i] > 5*train_err[i-1]:\n",
    "            break\n",
    "    return train_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_errors = train_rnn(train_data, n_epoch)\n",
    "for i in range(0,len(train_data[0])):\n",
    "    temp = np.zeros([1,256],dtype=dtype);\n",
    "    temp[0] = train_data[0][i]\n",
    "    sys.stdout.write(chr(pred_rnn_fn(temp)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEPCAYAAACk43iMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7239360f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_learning_curve(train_err):\n",
    "    plt.plot(np.arange(n_epoch), train_errors, 'b-')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('error')\n",
    "    plt.show()\n",
    "plot_learning_curve(train_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
